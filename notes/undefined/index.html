<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="generator" content="Eleventy">
  <link href="https://github.com/NZ99" rel="me">
  <link rel="webmention" href="https://webmention.io/www.finmoorhouse.com/webmention">
  <link rel="pingback" href="https://webmention.io/www.finmoorhouse.com/xmlrpc">
  <meta property="og:type" content="website">
  <meta name="author" content="Niccolò Zanichelli">
  <meta name="theme-color" content="#333948">
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  <!-- Analytics -->
  <script defer data-domain="finmoorhouse.com" src="https://plausible.io/js/script.js"></script>
  
  <!-- Twitter meta tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@ncznc">
  <meta name="twitter:creator" content="Niccolò Zanichelli">

  <!-- Description -->
  
  <meta name="twitter:description" content="Niccolò Zanichelli&#39;s website">
  <meta name="description" content="Niccolò Zanichelli&#39;s website">
  <meta property="og:description" content="Niccolò Zanichelli&#39;s website">
    

  <!-- Title -->
  
  <meta name="twitter:title" content="Fin Moorhouse">
  <meta property="og:title" content="Fin Moorhouse">
  
  
  <!-- Share image -->
  
  <meta name="twitter:image" content="https://images.finmoorhouse.com/share-images/share-4.png">
  <meta property="og:image" content="https://images.finmoorhouse.com/share-images/share-4.png">
  <meta name="image" content="https://images.finmoorhouse.com/share-images/share-4.png">
  
  
  

  <!-- Additional styling -->
  <link rel="stylesheet" href="/nz/global-processed.css"/>
  
  
      <link rel="stylesheet" href="/nz/style/writing.css"/>
      
      <link rel="stylesheet" href="https://unpkg.com/katex@latest/dist/katex.min.css"/>
      
  

  <title>Niccolò Zanichelli</title>
</head>
<body id="top" class="bg-flint-500 text-slate-50">
  <nav class="flex flex-row max-w-lg mx-auto justify-between py-4 text-sm px-4">
    <header class="flex flex-none opacity-50 hover:underline decoration-dotted"><a href="/">Niccolò Zanichelli</a></header>
    <ul class="flex flex-none gap-x-4">
    
    <li class="inline"><a href="/nz/"
      
      class="opacity-50 hover:underline decoration-dotted"
       target="_self">Home</a>
    </li>
    
    <li class="inline"><a href="/nz/writing"
      
      class="opacity-50 hover:underline decoration-dotted"
       target="_self">Writing</a>
    </li>
    
    <li class="inline"><a href="/nz/notes"
      
      class="opacity-50 hover:underline decoration-dotted"
       target="_self">Notes</a>
    </li>
    
    <li class="inline"><a href="/nz/projects"
      
      class="opacity-50 hover:underline decoration-dotted"
       target="_self">Projects</a>
    </li>
    
  </ul></nav>
  <main class="prose tablet:prose-lg prose-invert font-inter pt-12 pb-12">
    
<h1 class="mb-4"></h1>

<p class="font-sans">
  February 2024
</p>
 <div class="mb-6">
    <a
      href="/notes"
      class="flex items-center gap-1.5 bg-slate-600 text-sm font-semibold text-white px-2.5 py-0.5 rounded-full max-w-max no-underline font-medium font-sans"
    >
      <svg
        xmlns="http://www.w3.org/2000/svg"
        width="1em"
        height="1em"
        fill="white"
        viewBox="0 0 256 256"
      >
        <rect width="256" height="256" fill="none"></rect>
        <polyline
          points="160 208 80 128 160 48"
          fill="none"
          stroke="currentColor"
          stroke-linecap="round"
          stroke-linejoin="round"
          stroke-width="24"
        ></polyline>
      </svg>
      <span>Back to notes</span>
    </a>
  </div> 

<details
  class="block desktop:hidden text-sm bg-flint-400 rounded-md px-8 py-4 font-sans mb-4 ring-slate-600 hover:ring-1"
>
  <summary class="text-md cursor-pointer font-medium">
    Contents
    <span class="hidde sm:inline opacity-70 serif"> (click to toggle)</span>
  </summary>
  <nav class="toc" >
        <ol><li><a href="#title%3A-evaluating-awareness-in-ai-systems">title: Evaluating awareness in AI systems</a></li></ol>
      </nav>
</details>

<div class="side-nav opacity-60 text-sm hidden font-sans hover:opacity-100">
  <div class="side-nav-offset hidden desktop:block overflow-hidden">
    <h2>Contents</h2>
    <p>698 words, 4 min read</p>
    <nav class="toc" >
        <ol><li><a href="#title%3A-evaluating-awareness-in-ai-systems">title: Evaluating awareness in AI systems</a></li></ol>
      </nav>
    <br />
    <a
      href="#top"
      class="inline-block no-underline rounded-sm outline outline-1 outline-slate-400/60 p-2 ml-2 hover:outline-slate-600 box-border"
      >Back to top &#8593;</a
    >
  </div>
</div>
 <hr>
<h2 id="title%3A-evaluating-awareness-in-ai-systems" tabindex="-1"><a class="header-anchor" href="#title%3A-evaluating-awareness-in-ai-systems">title: Evaluating awareness in AI systems</a></h2>
<p>tags: [notes]<br>
date: 2021-10-13<br>
permalink: /notes/evaluating_awareness_in_AI_systems</p>
<p>How can we evaluate 1. self awareness and 2. situational awareness more broadly in AI systems?</p>
<p>Some general points.</p>
<h1>Evaluating self-awareness</h1>
<ul>
<li>
<p>Self-awareness tests like the mirror self recognition one are based on the referent of the self-concept (if present): they work by modifying it (for example, by adding a red dot to the tested individual’s face) and by then verifying whether the individual is able to notice the difference.</p>
</li>
<li>
<p>It is not sufficient to have a self-concept at all: the concept needs to be <a href="https://arxiv.org/abs/2304.01481">grounded</a>. The python script</p>
<pre><code>print(&quot;I am self aware.&quot;)
</code></pre>
<p>should not pass a test of self awareness, and neither should a pre-trained base LLM, no matter how much more complex, uttering a similar statement<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. Humans (and other animals believed to be self-aware) develop self-awareness through interactions with the environment they are a part of, and neither the python script above nor a base LLM can be said to do so. However, once an LLM is finetuned via RLHF it becomes a far more promising candidate for the kind of referential grounding needed for true self awareness:</p>
<blockquote>
<p>[… T]he evaluation standards for the outputs of LLMs fine-tuned with RLHF are extra-linguistic, being determined by the normative criteria embedded in human feedback. Of particular interest for our discussion is the criterion of ‘honesty’ or ‘truthfulness’ commonly used in RLHF. This criterion ensures that the evaluation standards for the outputs of the fine-tuned model are world-involving, as they hinge on the actual state of the world. During RLHF fine-tuning, one of the LLM’s objective is to generate outputs accurately reflecting real-world facts, receiving ‘rewards’ for success and ‘punishments’ for failure. The learning process is thus partly driven by the degree to which the generated outputs match reality, endowing the model with the ultimate function of producing factually correct statements. […] This ultimate function is the missing ingredient for referential grounding, providing RLHF fine-tuned LLMs with the kind of descriptive normativity essential to meaning. […] The system’s accuracy is irrelevant; the crucial factor is the presence of a representational world-involving function.</p>
</blockquote>
<p>So it would look like RLHF’d LLMs to be capable of some degree of <em>grounded</em> self awareness. Do current LLMs like GPT-4 have it? I’m not sure, but I do think they do have <a href="https://twitter.com/MatthewJBar/status/1736140781050790066">some degree of situational awareness</a>.</p>
</li>
<li>
<p>It is important to note that self awareness is not a binary feature. It is a spectrum. And so is situational awareness. For example, <a href="https://www.sciencedirect.com/science/article/pii/S0376635717300104">dogs fail the vision-based mirror self-recognition test, but pass it when modified in a modified “olfactory mirror” one</a>. Any test for self awareness in AI systems should take this into account.</p>
</li>
<li>
<p>All tests I am able to find in the context of testing animal self-awareness are behavioral. This is to be expected, as the level of access we enjoy w.r.t. AI systems is unprecedented in biological ones. However, this still leaves open the question of what evaluation suites integrating both behavioral <em>and</em> interpretability-based tests could look like.</p>
</li>
</ul>
<h1>A mirror test for simulacra: a proposal</h1>
<p>So, the mirror self-recognition test works by tampering with the referent of an individual’s self-concept. Can we do the same with the simulacra inside a language model? One way to go about it might be to tamper with the model’s previous responses in the conversation history and to check whether it is able to notice. After sampling each model’s responses we would sometime randomly replace Here is the kind of conversation taht I have in mind</p>
<blockquote>
<p>USER<br>
What are you?</p>
<p>MODEL<br>
I am a language model</p>
</blockquote>
<p>It would probably be important for the conversation to first elicit some relevant situational awareness, including the kind of access the user enjoys with respect to 1. the model and 2. the conversation itself.</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://twitter.com/repligate/status/1723864725077782962">Janus ponders</a> how situational awareness of end of text tokens is developed in GPT models, and whether base LLMs are somehow aware of them (and their function) too. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

<div class="mb-6">
    <a
      href="/notes"
      class="flex items-center gap-1.5 bg-slate-600 text-sm font-semibold text-white px-2.5 py-0.5 rounded-full max-w-max no-underline font-medium font-sans"
    >
      <svg
        xmlns="http://www.w3.org/2000/svg"
        width="1em"
        height="1em"
        fill="white"
        viewBox="0 0 256 256"
      >
        <rect width="256" height="256" fill="none"></rect>
        <polyline
          points="160 208 80 128 160 48"
          fill="none"
          stroke="currentColor"
          stroke-linecap="round"
          stroke-linejoin="round"
          stroke-width="24"
        ></polyline>
      </svg>
      <span>Back to notes</span>
    </a>
  </div>

    
  </main>
</body>
</html>